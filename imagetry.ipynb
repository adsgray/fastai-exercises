{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and testing set\n",
    "# define shuffle data loader?\n",
    "# got csv files from https://pjreddie.com/projects/mnist-in-csv/\n",
    "HOME=\"/home/adsgray\"\n",
    "DIR=HOME + \"/code/mnist\"\n",
    "TRAINING=DIR + \"/mnist_train.csv\"\n",
    "TESTING=DIR + \"/mnist_test.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingfile = open(TRAINING, \"r\")\n",
    "testingfile = open(TESTING, \"r\")\n",
    "traininglines = trainingfile.readlines()\n",
    "testinglines = testingfile.readlines()\n",
    "\n",
    "def tensor_from_string(s):\n",
    "    l = [int(i) for i in s.split(\",\")]\n",
    "    #map(int, l)\n",
    "    return tensor(l)\n",
    "\n",
    "    \n",
    "training_raw = torch.stack([tensor_from_string(s) for s in traininglines])\n",
    "testing_raw = torch.stack([tensor_from_string(s) for s in testinglines])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_labels = training_raw[:,0]\n",
    "training_images = training_raw[:,1:].float()/255\n",
    "\n",
    "testing_labels = testing_raw[:,0]\n",
    "testing_images = testing_raw[:,1:].float()/255\n",
    "#show_image(t[0].view(28,28))\n",
    "#testing_labels[59]\n",
    "#show_image(testing_images[59].view(28,28))\n",
    "\n",
    "testing_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to select a random sample\n",
    "import random\n",
    "\n",
    "def random_indexes(num, max):\n",
    "    return [random.randrange(0,max) for i in range(num)]\n",
    "\n",
    "def training_sample(num):\n",
    "    max = training_images.shape[0]\n",
    "    idxs = random_indexes(num, max)\n",
    "    return [(training_images[idxs], training_labels[idxs])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost function\n",
    "\n",
    "from torch import exp\n",
    "def softmax(x): return exp(x) / exp(x).sum(dim=1, keepdim=True)\n",
    "def sigmoid(x): return 1/(1+torch.exp(-x))\n",
    "\n",
    "fudge=1.\n",
    "\n",
    "def mnist_loss(predictions, targets):\n",
    "    return F.nll_loss(F.log_softmax(predictions, dim=1), targets)\n",
    "\n",
    "    \n",
    "def mnist_loss2(predictions, targets):\n",
    "    lp = torch.log(predictions)\n",
    "    sm = softmax(lp)\n",
    "    #print(\"sm: \", sm)\n",
    "    predictions = -sm\n",
    "    #predictions = softmax(predictions)\n",
    "    return predictions[range(targets.shape[0]), targets].mean()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "\n",
    "width=400\n",
    "w1 = init_params((28*28,width))\n",
    "b1 = init_params(width)\n",
    "w2 = init_params((width,10))\n",
    "b2 = init_params(10)\n",
    "\n",
    "params = (w1,b1,w2,b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define simple network\n",
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1\n",
    "    # relu\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_acc = True\n",
    "incorrect=list()\n",
    "badguesses=list()\n",
    "correct=list()\n",
    "\n",
    "def accuracy(preds, x, y):\n",
    "    prednums = preds[range(y.shape[0]),y]\n",
    "    maxes = torch.max(preds, dim=1)\n",
    "    cor = prednums == maxes.values\n",
    "    incor = [i for i,j in zip(x,cor) if not j]\n",
    "    wrongguess = [g for g,j in zip(preds,cor) if not j]\n",
    "    c = [y for y,j in zip(y,cor) if not j]\n",
    "    incorrect.extend(incor)\n",
    "    badguesses.extend(wrongguess)\n",
    "    correct.extend(c)\n",
    "    acc = cor.float().mean()\n",
    "    return acc\n",
    "    \n",
    "\n",
    "\n",
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    acc = accuracy(preds, xb, yb)\n",
    "    if print_acc: \n",
    "        print(acc)\n",
    "    #print(\"preds: \", preds)\n",
    "    #print(\"yb: \", yb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    print(\"loss: \", loss)\n",
    "    loss.backward()\n",
    "    \n",
    "def train_epoch_internal(model, lr, params, dl):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            #print(\"grad: \", p.grad)\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()\n",
    "            \n",
    "    \n",
    "def train_epoch(size, model, lr, params):\n",
    "    dl = training_sample(size)\n",
    "    train_epoch_internal(model, lr, params, dl)\n",
    "\n",
    "def train_on_incorrect(model, lr, params):\n",
    "    dl = [(torch.stack(incorrect), torch.stack(correct))]\n",
    "    train_epoch_internal(model, lr, params, dl)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 2, 4, 3, 3, 1, 7, 9, 5, 5, 6, 7, 3, 5, 8, 5, 5, 7, 8, 3, 6, 9, 7, 9, 0, 4, 8, 3, 8, 3, 2, 3, 7, 2, 2, 3, 9, 2, 8, 3, 2, 4, 3, 8, 8, 2, 9, 3, 5, 3, 8, 7, 4, 6, 5, 0, 8, 6, 8, 2, 3, 8, 4, 7,\n",
       "        7, 8, 1, 5, 2, 5, 8, 7, 0, 8, 8, 7, 2, 5, 4, 8, 4, 9, 7, 8, 7, 8, 5, 5, 2, 3, 8, 2, 0, 3, 5, 3, 8, 4, 9, 3, 1, 3, 8, 5, 1, 8, 8, 2, 2, 5, 2, 9, 2, 0, 5, 2, 5, 8, 3, 8, 5, 8, 3, 3, 3, 6, 7, 0,\n",
       "        3, 4, 7, 4, 2, 6, 6, 5, 4, 6, 2, 2, 3, 9, 2, 4, 6, 7, 5, 9, 7, 7, 5, 5, 5, 3, 2, 9, 8, 0, 2, 7, 9, 5, 3, 3, 5, 7, 3, 3, 7, 3, 2, 7, 3, 0, 6, 7, 9, 9, 7, 9, 1, 6, 9, 6, 9, 9, 5, 7, 3, 0, 1, 8,\n",
       "        9, 8, 9, 6, 9, 0, 5, 4, 8, 8, 6, 8, 6, 6, 3, 7, 4, 2, 9, 7, 3, 6, 1, 5, 5, 3, 9, 8, 6, 3, 4, 7, 5, 9, 5, 7, 3, 3, 9, 5, 4, 8, 8, 4, 9, 2, 7, 1, 3, 7, 6, 3, 3, 3, 0, 7, 5, 3, 7, 6, 6])"
      ]
     },
     "execution_count": 1029,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-160.2745, -137.6411,   38.1698,   57.9568,  -40.3304,   -7.5785, -222.9984,   29.2445,   72.1851,  112.6661], grad_fn=<UnbindBackward>)\n",
      "guess:  tensor(9)\n",
      "actual:  tensor(3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAI7ElEQVR4nO2bW28bRRuAn7XXWZ8PSZu4ce1Esd1GuGqDq6QtpBKFKySEkOC2EhISf4L/gcQtXIDETSUOAiSS0BQoQkDapHFIE9PQ4sQKiR03PuzJ+130837YTdq0Wrvhk5/L3Z3d2ccz78y8OxYMw6DL/7A96wocNrpCWugKaaErpIWukBbEx5z/fx6ChL0OdltIC10hLXSFtNAV0kJXSAtdIS10hbTQFdJCV0gLXSEtPG7q3nYURUGWZcrlMuVyGVVVURTloesMw0AQBPr6+nC73TidTkRRxG63Y7NZ97s+cyGFQoHbt28zMzPDtWvXyGazrK+v73mt3W7n7bff5uzZs5w/f54jR47g9Xr/nUJ0XUfTNGRZplQqoes6iqKQzWaZm5tjaWmJP/74g62tLcrl8kPlDcPAZrOxsrKCzWYjEokgCAJOpxOHw2FZPTsmRFVVdnZ2WF5e5ssvv2Rra4t8Pk82m+XOnTtomoaqquyX4xWEB4vTr7/+munpaQRBYHx8nN7eXlwul2X1bJsQwzDQdR1ZlikWi2xubvL777+zvLzM8vIyhUKBzc1Ntra2kGWZer1uymi8/F7U63WzZYmiyOTkJL29vZbVW3hM1v2p8yGN7nH37l2uXLnCwsICn3/+uRk0G8992qy/0+nE7/fz1VdfcebMmae5xZ7W29ZCNE2jWCyytrbG/Pw8KysrVKtV6vU69Xodp9OJ1+vF5XLh8XiIRqP09/fjcrmauoCu6+i6zvT0NMvLy+bxer2OpmlPLXQ/2iakVqtx+/Ztrl27xqefftrUJQCCwSDxeJxIJEI4HObixYs8//zzhEIhPB6PeV0jtrz33ntNQtqF5UIURWF3d5e1tTWmp6dZWlqiXq/jcDhwu90MDAwQj8eJRqOMjIzQ39/P4OAg0WiUUCiE0+nEbrdjGAaGYZgtQdf1pudIkoTH48Fut1taf8uF1Go1FhYWmJ2d5YMPPqBcLmMYBm63m0gkwuTkJK+++irDw8PEYjEkSUKSpIcCqa7r1Ot1ZFnm/v371Gq1pvNut5tQKIQoWvsKlt1NVVXK5TJra2t88cUXZLNZKpUKmqYBkEqleOutt0gmk5w4cQK/348kSdjt9j1HFVmWqdVqzM3N8csvv5DJZMxzNpuNdDrNiRMn8Hq9Vr0CYKGQxlB49epV3n//fWq1GvV63Tw/Pj7Ou+++iyiKB/pVy+UyGxsbfPjhh3z00UdN52w2G+fOneOll14iEAhY9QqAhUI0TePevXvk83l0XTcDaDgcJp1Ok0qlnmjdUa1W+fvvv6lUKk3HJUnC6XQSCATw+XyHN4bIskwmkyGXyzUNh/F4nNdff510Oo0oio+cdP2T3d1dVldXKRaLTccb849QKITP57N0HQMdmLoLgnDglmEYBru7uxSLRb7//nuuXr1KNpt9UFFRxOFw8Morr5BIJDh9+jRHjhw5vEF1P2w2Gw6H47FCGsPs5uYmN2/eZGpqis8++8xMBTgcDjweDy+++CKXLl0iHo9bHlDBQiGSJJFKpVAUhVgsht/vJ5FIMDo6ysjICH6//5HdZXd3l+3tbWZmZpienubGjRsoimIG5tHRUZLJJOl0mmg0Sk9Pj1VVb8IyIT09PYyMjFCtVkkmkwwODnLu3DmGhoY4duwYPp/vkeULhQI3b97k22+/5ZNPPmk6JwgCo6OjnD17lng8bulirhXLhIiiSCQSwePx4Pf78fl8hMNhXC4XXq9335zFzs4O+Xye2dlZvvvuO+bm5oAHLa6np4djx47R39/PpUuXuHDhguXD7EPvYdWNHA6HORSGw2EzdjyO7e1trl+/ztTUFFeuXEFVVeBBi/N4PJw8eZKhoSEmJiZIJBKWB9FWLL+7IAhPNLyur6/zzTffcOvWLVRVNWPGwMAAyWSS1157jYmJCWKx2L6zWitpi5AnmSzlcjlmZmbMtGKDgYEBhoeHeeGFF3juueesrua+PPMk836Mj4/z5ptvEg6HO/rcQyskHo+TSqUszZcehEP7oapQKLC9vW0G2U5xaIS0zmQrlQo7OztmJr5TO66feZdpDK+qqlKpVMxU49TUFPl8ntOnT5NIJEin0xw9ehSbzdbWkeZQCAkGg+bnTFVV0TSNpaUl7t69S6FQ4M6dO8RiMXp7exEEoa1C2vYZ4qAUi0Xu3bvHwsICN27cYHZ2lh9//NFMJAWDQbxeL5cvX2ZycpKxsTGCwaAVj+7sZ4hH8c8fIRAIEAwG8fl8uN1u/vzzT65fv46maWiaxsbGBoIgsLi4iCRJxONxAoFA21pJx4XIsky1WkXXdVRVxev14na76evrY3x8nPn5ecLhMDs7O2a2zDAMfvrpJ9bX17lw4QK9vb1IktSWaXzHhWiaRqlUMpPIdrsdl8tlxpKjR4/i8/moVqtN6cPGEFwsFtE07fAv/w9KLpfj448/5q+//iKbzfLOO+/wxhtvmN1IFEX8fj+FQqGpXDQaJR6P09/fT09Pj+WpwwYdFWIYBsVikcXFRRYXF7l16xYXL15s+tarKMqeQ2swGKSvrw+Xy9XWRV5Ht0PUajXy+Ty5XI5SqQTA6uoqP//8M5lMhpWVFX777TcymQyyLJtlBUEgHA4zNDSE3+9/otX0k9LRDTO1Wo1SqUSpVDJzpdvb2ywuLjI/P8+vv/7K+vo61Wr1QeX+m1h2OBxmfGlnd4EOClEUhVwux8rKCqurq6aQH374gUwmQ7VapVqtEgqFGBsbM8udP3+eZDLJxMQEg4ODhEKhttazY0IMw0BVVXN/SCMR1NgiIYoikiQRiUQYGhoyy6VSKU6dOsXx48cJBAL/vozZfkiSxPHjx0kmkyQSCba2ttjc3GRycpKXX34Zt9uNx+NhbGyMWCzWVM7hcJg7Dv91GbP9sNlsuFwuIpEIp06dYmNjA7fbzcmTJzlz5gwejweXy8Xw8DB9fX2dqtZDdGwt09jroSgKlUrF3BnUmJQ1Fm0H/RhuAXs2tWe+uHuGdP9zdxC6Qlp4XGdtb0g/hHRbSAtdIS10hbTQFdJCV0gLXSEt/AdWisTwz50STQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=2\n",
    "show_image(incorrect[n].view(28,28))\n",
    "print(badguesses[n])\n",
    "print(\"guess: \", torch.argmax(badguesses[n]))\n",
    "print(\"actual: \", correct[n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "preds:  tensor([[  91.2155,   62.7811,  -96.8800,  156.0607, -109.4726,  114.4049,   16.1433,  -37.5896,   22.5697,  -48.0186]], grad_fn=<AddBackward0>)\n",
      "tensor([5])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = training_sample(1)\n",
    "\n",
    "for (d,y) in t:\n",
    "    p = simple_net(d)\n",
    "    #print(d.shape)\n",
    "    show_image(d.view(28,28))\n",
    "    print(\"preds: \", p)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3761)\n",
      "loss:  tensor(39.8116, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "#https://stackoverflow.com/questions/60032073/select-specific-rows-of-2d-pytorch-tensor\n",
    "\n",
    "\n",
    "#def mse(preds, targets): return ((preds-targets)**2).mean().sqrt()\n",
    "#def linear1(xb): return xb@weights + bias\n",
    "\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "lr = 0.08\n",
    "num=1\n",
    "size=3000\n",
    "# train\n",
    "def train_model(size, model, params, lr, num):\n",
    "    for i in range(num):\n",
    "        train_epoch(size, model, lr, params)\n",
    "       \n",
    "\n",
    "\n",
    "#print(params)\n",
    "#train_model(size, simple_net, params, lr, num)\n",
    "\n",
    "train_on_incorrect(simple_net, lr, params)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out model to disk\n",
    "import pickle\n",
    "\n",
    "def save_model():\n",
    "    model = {'w1':w1, 'b1': b1, 'w2':w2, 'b2': b2}\n",
    "    with open('mymodel.pkl', 'wb') as handle:\n",
    "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_model():\n",
    "    with open('filename.pickle', 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    w1 = model['w1']\n",
    "    b1 = model['b1']\n",
    "    w2 = model['w2']\n",
    "    b2 = model['b2']\n",
    "\n",
    "\n",
    "    \n",
    "save_model()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
