{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and testing set\n",
    "# define shuffle data loader?\n",
    "# got csv files from https://pjreddie.com/projects/mnist-in-csv/\n",
    "HOME=\"/home/adsgray\"\n",
    "DIR=HOME + \"/code/mnist\"\n",
    "TRAINING=DIR + \"/mnist_train.csv\"\n",
    "TESTING=DIR + \"/mnist_test.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingfile = open(TRAINING, \"r\")\n",
    "testingfile = open(TESTING, \"r\")\n",
    "traininglines = trainingfile.readlines()\n",
    "testinglines = testingfile.readlines()\n",
    "\n",
    "def tensor_from_string(s):\n",
    "    l = [int(i) for i in s.split(\",\")]\n",
    "    #map(int, l)\n",
    "    return tensor(l)\n",
    "\n",
    "    \n",
    "training_raw = torch.stack([tensor_from_string(s) for s in traininglines])\n",
    "testing_raw = torch.stack([tensor_from_string(s) for s in testinglines])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_labels = training_raw[:,0]\n",
    "training_images = training_raw[:,1:].float()/255\n",
    "\n",
    "testing_labels = testing_raw[:,0]\n",
    "testing_images = testing_raw[:,1:].float()/255\n",
    "#show_image(t[0].view(28,28))\n",
    "#testing_labels[59]\n",
    "#show_image(testing_images[59].view(28,28))\n",
    "\n",
    "testing_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to select a random sample\n",
    "import random\n",
    "\n",
    "def random_indexes(num, max):\n",
    "    return [random.randrange(0,max) for i in range(num)]\n",
    "\n",
    "def training_sample(num):\n",
    "    max = training_images.shape[0]\n",
    "    idxs = random_indexes(num, max)\n",
    "    return [(training_images[idxs], training_labels[idxs])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost function\n",
    "\n",
    "from torch import exp\n",
    "def softmax(x): return exp(x) / exp(x).sum(dim=1, keepdim=True)\n",
    "def sigmoid(x): return 1/(1+torch.exp(-x))\n",
    "\n",
    "fudge=1.\n",
    "\n",
    "def mnist_loss(predictions, targets):\n",
    "    return F.nll_loss(F.log_softmax(predictions, dim=1), targets)\n",
    "\n",
    "    \n",
    "def mnist_loss2(predictions, targets):\n",
    "    lp = torch.log(predictions)\n",
    "    sm = softmax(lp)\n",
    "    #print(\"sm: \", sm)\n",
    "    predictions = -sm\n",
    "    #predictions = softmax(predictions)\n",
    "    return predictions[range(targets.shape[0]), targets].mean()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "\n",
    "width=400\n",
    "w1 = init_params((28*28,width))\n",
    "b1 = init_params(width)\n",
    "w2 = init_params((width,10))\n",
    "b2 = init_params(10)\n",
    "\n",
    "params = (w1,b1,w2,b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define simple network\n",
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1\n",
    "    # relu\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_acc = True\n",
    "incorrect=list()\n",
    "badguesses=list()\n",
    "correct=list()\n",
    "\n",
    "def accuracy(preds, x, y):\n",
    "    prednums = preds[range(y.shape[0]),y]\n",
    "    maxes = torch.max(preds, dim=1)\n",
    "    cor = prednums == maxes.values\n",
    "    incor = [i for i,j in zip(x,cor) if not j]\n",
    "    wrongguess = [g for g,j in zip(preds,cor) if not j]\n",
    "    c = [y for y,j in zip(y,cor) if not j]\n",
    "    incorrect.extend(incor)\n",
    "    badguesses.extend(wrongguess)\n",
    "    correct.extend(c)\n",
    "    acc = cor.float().mean()\n",
    "    return acc\n",
    "    \n",
    "\n",
    "\n",
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    acc = accuracy(preds, xb, yb)\n",
    "    if print_acc: \n",
    "        print(acc)\n",
    "    #print(\"preds: \", preds)\n",
    "    #print(\"yb: \", yb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    print(\"loss: \", loss)\n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "def train_epoch(size, model, lr, params):\n",
    "    dl = training_sample(size)\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            #print(\"grad: \", p.grad)\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guess:  tensor(5)\n",
      "actual:  tensor(3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=24\n",
    "show_image(incorrect[n].view(28,28))\n",
    "print(\"guess: \", torch.argmax(badguesses[n]))\n",
    "print(\"actual: \", correct[n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:  tensor([[ -33.0913, -101.7266, -130.7633,  -61.0670,  190.0876,   59.2970,  -88.8163,   11.2021,   17.7532,  118.9505]], grad_fn=<AddBackward0>)\n",
      "tensor([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = training_sample(1)\n",
    "\n",
    "for (d,y) in t:\n",
    "    p = simple_net(d)\n",
    "    #print(d.shape)\n",
    "    show_image(d.view(28,28))\n",
    "    print(\"preds: \", p)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9093)\n",
      "loss:  tensor(3.1909, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "#https://stackoverflow.com/questions/60032073/select-specific-rows-of-2d-pytorch-tensor\n",
    "\n",
    "\n",
    "#def mse(preds, targets): return ((preds-targets)**2).mean().sqrt()\n",
    "#def linear1(xb): return xb@weights + bias\n",
    "\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "lr = 0.08\n",
    "num=1\n",
    "size=3000\n",
    "# train\n",
    "def train_model(size, model, params, lr, num):\n",
    "    for i in range(num):\n",
    "        train_epoch(size, model, lr, params)\n",
    "       \n",
    "\n",
    "\n",
    "#print(params)\n",
    "train_model(size, simple_net, params, lr, num)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out model to disk\n",
    "import pickle\n",
    "\n",
    "def save_model():\n",
    "    model = {'w1':w1, 'b1': b1, 'w2':w2, 'b2': b2}\n",
    "    with open('mymodel.pkl', 'wb') as handle:\n",
    "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_model():\n",
    "    with open('filename.pickle', 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    w1 = model['w1']\n",
    "    b1 = model['b1']\n",
    "    w2 = model['w2']\n",
    "    b2 = model['b2']\n",
    "\n",
    "\n",
    "    \n",
    "save_model()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
