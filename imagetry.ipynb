{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and testing set\n",
    "# define shuffle data loader?\n",
    "# got csv files from https://pjreddie.com/projects/mnist-in-csv/\n",
    "HOME=\"/home/adsgray\"\n",
    "DIR=HOME + \"/code/mnist\"\n",
    "TRAINING=DIR + \"/mnist_train.csv\"\n",
    "TESTING=DIR + \"/mnist_test.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingfile = open(TRAINING, \"r\")\n",
    "testingfile = open(TESTING, \"r\")\n",
    "traininglines = trainingfile.readlines()\n",
    "testinglines = testingfile.readlines()\n",
    "\n",
    "def tensor_from_string(s):\n",
    "    l = [int(i) for i in s.split(\",\")]\n",
    "    #map(int, l)\n",
    "    return tensor(l)\n",
    "\n",
    "    \n",
    "training_raw = torch.stack([tensor_from_string(s) for s in traininglines])\n",
    "testing_raw = torch.stack([tensor_from_string(s) for s in testinglines])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_labels = training_raw[:,0]\n",
    "training_images = training_raw[:,1:].float()/255\n",
    "\n",
    "testing_labels = testing_raw[:,0]\n",
    "testing_images = testing_raw[:,1:].float()/255\n",
    "#show_image(t[0].view(28,28))\n",
    "#testing_labels[59]\n",
    "#show_image(testing_images[59].view(28,28))\n",
    "\n",
    "testing_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to select a random sample\n",
    "import random\n",
    "\n",
    "def random_indexes(num, max):\n",
    "    return [random.randrange(0,max) for i in range(num)]\n",
    "\n",
    "def training_sample(num):\n",
    "    max = training_images.shape[0]\n",
    "    idxs = random_indexes(num, max)\n",
    "    return [(training_images[idxs], training_labels[idxs])]\n",
    "  \n",
    "\n",
    "\n",
    "#samp = training_sample(3)\n",
    "#samp\n",
    "#for (x,y) in samp:\n",
    "#    show_image(x.view(28,28))\n",
    "#    print(y)\n",
    "#samp\n",
    "#idxs = random_indexes(100, 6000)\n",
    "#samples = training_images[idxs]\n",
    "#labels = training_labels[idxs]\n",
    "#show_image(samples[0].view(28,28))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost function\n",
    "\n",
    "\n",
    "targs = tensor([\n",
    "    [1,0,0,0,0,0,0,0,0,0],\n",
    "    [0,1,0,0,0,0,0,0,0,0],\n",
    "    [0,0,1,0,0,0,0,0,0,0],\n",
    "    [0,0,0,1,0,0,0,0,0,0],\n",
    "    [0,0,0,0,1,0,0,0,0,0],\n",
    "    [0,0,0,0,0,1,0,0,0,0],\n",
    "    [0,0,0,0,0,0,1,0,0,0],\n",
    "    [0,0,0,0,0,0,0,1,0,0],\n",
    "    [0,0,0,0,0,0,0,0,1,0],\n",
    "    [0,0,0,0,0,0,0,0,0,1]   \n",
    "])\n",
    "\n",
    "\n",
    "# take targets like [5,2,1] and turn them into [0,0,0,1,...]\n",
    "# actually don't have to do this...\n",
    "def expand_targets(targets):\n",
    "    return torch.stack([targs[t] for t in targets])\n",
    "\n",
    "#targets = tensor([5,2,1])\n",
    "#expanded_targets = expand_targets(targets)\n",
    "\n",
    " \n",
    "from torch import exp\n",
    "def softmax(x): return exp(x) / exp(x).sum(dim=1, keepdim=True)\n",
    "def sigmoid(x): return 1/(1+torch.exp(-x))\n",
    "\n",
    "def mnist_loss(predictions, targets):  \n",
    "    predictions = -torch.log(softmax(predictions))\n",
    "    return predictions[range(targets.shape[0]), targets]\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "\n",
    "w1 = init_params((28*28,30))\n",
    "b1 = init_params(30)\n",
    "w2 = init_params((30,10))\n",
    "b2 = init_params(10)\n",
    "\n",
    "params = (w1,b1,w2,b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define simple network\n",
    "def simple_net(xb): \n",
    "    res = xb@w1 + b1\n",
    "    # relu\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = training_sample(5)\n",
    "print_acc = True\n",
    "def accuracy(preds, y):\n",
    "    prednums = preds[range(y.shape[0]),y]\n",
    "    maxes = torch.max(preds, dim=1)\n",
    "    cor = prednums == maxes.values\n",
    "    acc = cor.float().mean()\n",
    "    return acc\n",
    "    \n",
    "\n",
    "\n",
    "def calc_grad(xb, yb, simple_net):\n",
    "    preds = model(xb)\n",
    "    acc = accuracy(preds, yb)\n",
    "    if print_acc: print(acc)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-111-a1bf731ac898>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-111-a1bf731ac898>\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    def train_model(model, params, lr, num)\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "#https://stackoverflow.com/questions/60032073/select-specific-rows-of-2d-pytorch-tensor\n",
    "\n",
    "\n",
    "#def mse(preds, targets): return ((preds-targets)**2).mean().sqrt()\n",
    "#def linear1(xb): return xb@weights + bias\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "for x,y in dl:\n",
    "    pred = model(x)\n",
    "    loss = loss_func(pred, y)\n",
    "    loss.backward()\n",
    "    parameters -= parameters.grad * lr\n",
    "\n",
    "\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "# train\n",
    "def train_model(model, params, lr, num)\n",
    "for i in range(num):\n",
    "    train_epoch(model, lr, params)\n",
    "    print(validate_epoch(model), end=' ')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out model to disk\n",
    "import pickle\n",
    "\n",
    "def save_model():\n",
    "    model = {'w1':w1, 'b1': b1, 'w2':w2, 'b2': b2}\n",
    "    with open('mymodel.pkl', 'wb') as handle:\n",
    "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_model():\n",
    "    with open('filename.pickle', 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    w1 = model['w1']\n",
    "    b1 = model['b1']\n",
    "    w2 = model['w2']\n",
    "    b2 = model['b2']\n",
    "\n",
    "\n",
    "    \n",
    "save_model()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
